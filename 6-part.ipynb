{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10318214,"sourceType":"datasetVersion","datasetId":6388104}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nprint(sorted(os.listdir()))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-G1KwFUhSuMz","outputId":"91f83bb9-23e3-419d-c472-614eb14ab650","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n\n# file_path = \"C:/Users/Administrator/Desktop/SFMAP/fintech_LLM/v2/06_finetuning/instruction-data.json\"\nfile_path = \"/kaggle/input/instructions/instruction-data.json\"\n\nwith open(file_path, \"r\") as file:\n    data = json.load(file)\nprint(\"Number of entries:\", len(data))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJhnArIrP8Lz","outputId":"cadd8a8d-d7b9-4c20-a955-a301e490fc84","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Example entry:\\n\", data[50])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0YpxhuP0P9C7","outputId":"2dc866e2-4c7b-4db6-bb16-491c816574e6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Another example entry:\\n\", data[199])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-w9Kixt-P_Oj","outputId":"cea94180-16a4-4b3d-c088-6c76068a0ce3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def format_input(entry):\n    instruction_text = (\n        f\"Below is an instruction that describes a task. \"\n        f\"Write a response that appropriately completes the request.\"\n        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n    )\n\n    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n\n    return instruction_text + input_text","metadata":{"id":"iAYKEbTzQB4K","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_input = format_input(data[50])\ndesired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n\nprint(model_input + desired_response)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxMsSC6QQFrr","outputId":"48a45e06-3615-485d-bcdb-07dca7012d5b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_input = format_input(data[99])\ndesired_response = f\"\\n\\n### Response:\\n{data[199]['output']}\"\n\nprint(model_input + desired_response)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fM47CKLEQH-U","outputId":"dfa321bb-ca1d-4f83-c70b-d97be10db96c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n\nfile_path = \"/kaggle/input/instructions/instruction-data.json\"\n\nwith open(file_path, \"r\") as file:\n    data = json.load(file)\nprint(\"Number of entries:\", len(data))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PwDCVfAFhh7","outputId":"d92a47f8-3b03-4197-d3e3-be95e21c129d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_portion = int(len(data) * 0.85)  # 85% for training\ntest_portion = int(len(data) * 0.15)    # 15% for testing\n\ntrain_data = data[:train_portion]\ntest_data = data[train_portion:]","metadata":{"id":"tQepkRMiGGLC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training set length:\", len(train_data))\nprint(\"Test set length:\", len(test_data))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22IWMm-TGOpB","outputId":"0f5174dc-9793-4b20-be1f-42ff592709f6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"train.json\", \"w\") as json_file:\n    json.dump(train_data, json_file, indent=4)\n\nwith open(\"test.json\", \"w\") as json_file:\n    json.dump(test_data, json_file, indent=4)","metadata":{"id":"gipO0V4EGSsL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install litgpt tqdm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vd65_FG6Gx36","outputId":"48d2e067-96d2-430d-dfbc-2ab96cc15497","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!litgpt finetune_lora microsoft/phi-2 \\\n  --data JSON \\\n  --data.val_split_fraction 0.1 \\\n  --data.json_path \"train.json\" \\\n  --train.epochs 3 \\\n  --train.log_interval 100 \\\n  --train.global_batch_size 1 \\\n  --train.micro_batch_size 1 \\\n  --train.lr_warmup_steps 1000 \\\n  --train.max_seq_length 512 \\\n  --precision bf16 \\\n  --devices 1 \\\n  --out_dir \"output\" \\\n  --logger_name \"csv\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gN4rrD84GS56","outputId":"f7697f57-88b5-45b4-aebd-ff84b46b9116","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def format_input(entry):\n    instruction_text = (\n        f\"Below is an instruction that describes a task. \"\n        f\"Write a response that appropriately completes the request.\"\n        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n    )\n\n    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n\n    return instruction_text + input_text\n\nprint(format_input(test_data[0]))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiP9ORgCGhxS","outputId":"33470c69-7f28-4bd1-c660-1caa680ddff7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from litgpt import LLM\n\nllm = LLM.load(\"microsoft/phi-2\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1QeHoNaGliR","outputId":"786c6e7e-3256-415c-887c-dab39e6e181f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor i in tqdm(range(len(test_data))):\n    response = llm.generate(test_data[i])\n    test_data[i][\"base_model\"] = response","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"KsZPldSMGpUp","outputId":"2c8eace5-8b03-41b5-fbb8-4c53012d8cba","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data[1]","metadata":{"id":"3JugHtlcGsYq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Define the folder path and output zip name\noutput_folder = \"/kaggle/working\"\nzip_file = \"/kaggle/working/output.zip\"\n\n# Compress the folder\nshutil.make_archive(base_name=zip_file.replace(\".zip\", \"\"), format=\"zip\", root_dir=output_folder)\n\nprint(\"Folder compressed to:\", zip_file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from litgpt import LLM\n\ndel llm\nllm2 = LLM.load(\"/kaggle/working/out/finetune/lora/final/\", device=\"cpu\")","metadata":{"id":"GarJfdy_G_mq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor i in tqdm(range(len(test_data))):\n    response = llm2.generate(test_data[i])\n    test_data[i][\"finetuned_model\"] = response","metadata":{"id":"4uzfxhzWHDx7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!litgpt evaluate out/finetune/lora/final --tasks \"mmlu_philosophy\" --batch_size 4","metadata":{"id":"LPKrzBHKLb2Y","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from importlib.metadata import version\n\npkgs = [\"tqdm\",    # Progress bar\n        ]\n\nfor p in pkgs:\n    print(f\"{p} version: {version(p)}\")","metadata":{"id":"heVkUU6kLhsR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\njson_file = \"test_response_before_after.json\"\n\nwith open(json_file, \"r\") as file:\n    json_data = json.load(file)\n\nprint(\"Number of entries:\", len(json_data))","metadata":{"id":"Ux-Fu1mgLkNC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"json_data[0]","metadata":{"id":"hBUqn1WELnIx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def format_input(entry):\n    instruction_text = (\n        f\"Below is an instruction that describes a task. Write a response that \"\n        f\"appropriately completes the request.\"\n        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n    )\n\n    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n    instruction_text + input_text\n\n    return instruction_text + input_text\n\nprint(format_input(json_data[0])) # input","metadata":{"id":"3pWIZAgaLqMf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"json_data[0][\"output\"]","metadata":{"id":"K_quYaICLzGT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"json_data[0][\"response_before\"]","metadata":{"id":"D65t9FpfLz9r","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from litgpt import LLM\n\nllm = LLM.load(\"meta-llama/Meta-Llama-3-8B-Instruct\")","metadata":{"id":"VyhFpbLNL3zJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\n\ndef generate_model_scores(json_data, json_key):\n    scores = []\n    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n        prompt = (\n            f\"Given the input `{format_input(entry)}` \"\n            f\"and correct output `{entry['output']}`, \"\n            f\"score the model response `{entry[json_key]}`\"\n            f\" on a scale from 0 to 100, where 100 is the best score. \"\n            f\"Respond with the integer number only.\"\n        )\n        score = llm.generate(prompt, max_new_tokens=50)\n        try:\n            scores.append(int(score))\n        except ValueError:\n            continue\n\n    return scores","metadata":{"id":"WXDw-klAL6H6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for model in (\"response_before\", \"response_after\"):\n\n    scores = generate_model_scores(json_data, model)\n    print(f\"\\n{model}\")\n    print(f\"Number of scores: {len(scores)} of {len(json_data)}\")\n    print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")","metadata":{"id":"M8ZKH8olL9F7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}